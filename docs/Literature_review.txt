Примеры моделей, созданных для детекции сгенерированных изображений:

-EfficientNet
		Нейросеть, на основе CNN. Google AI разработали серию архитектур моделей под названием EfficientNet. Эти модели отличаются высокой степенью эффективности и легко 	настраиваются. Они позволяют классифицировать изображения с высокой точностью, при этом потребляя минимальное количество ресурсов. EfficientNet стало значительным шагом вперед в 	развитии ИНС для классификации изображений и продолжает быть актуальным до сих пор. Отличается от других CNN тем, что: создает более глубокую сеть с большим количеством слоёв, 	создает более широкую 	сеть с большим количеством нейронов в каждом слое, использует увеличение входного изображения. Один из самых эффективных проектов по детекции изображений на 	данное время. (https://habr.com/ru/companies/sberbank/articles/828842/)
		В частности, модель EfficientNet-B7 достигает рекордной точности 84,3 % на ImageNet, при этом она в 8,4 раза меньше и в 6,1 раза быстрее при выводе данных, чем лучшая из 	существующих ConvNet. EfficientNets также хорошо справляются с задачей переноса и демонстрируют высочайшую точность на наборах данных CIFAR-100 (91,7 %), Flowers (98,8 %) и трёх 	других наборах данных для трансферного обучения, при этом имея на порядок меньше параметров. (https://arxiv.org/abs/1905.11946)

-ResNet
		Модель, на основе CNN. Предложена Microsoft в 2015. Рассчитана на устранение проблемы "Затухающего градиента", появляющейся при обучение других моделей CNN. Использует 	концепцию Остаточных блоков. Она заключается в том, чтобы соединять некоторые слои с другими, пропуская промежуточные. Это формирует остаточный блок. Остаточные сети создаются 	путём объединения этих остаточных блоков. Преимущество добавления такого типа соединения в том, что если какой-либо слой снижает производительность архитектуры, то он будет 	пропущен в процессе регуляризации. (https://www.geeksforgeeks.org/deep-learning/residual-networks-resnet-deep-learning/)
		Рассмотрим модель Resnet-v2, представленную в работе "Остаточные сети (ResNet) — глубокое обучение". В наборе данных ImageNet авторы используют 152-слойную сеть ResNet, 	которая в 8 раз глубже, чем VGG19, но при этом имеет меньше параметров. Ансамбль из этих сетей ResNet показал ошибку всего в 3,7% на тестовом наборе данных ImageNet. Это является 	достаточно хорошим результатом.

-Нейросеть на основе спектрального анализа
		Модель, использующая в своей основе спектральный анализ изображениий. Модель ищет некоторые артефакты, которые видны в спектральном анализе. Реализация, использующая 	датасет ImageNet достигает точности до 90%. Описана в работе "Any-resolution ai-generated image detection by spectral learning, in: CVPR." (https://arxiv.org/pdf/2411.19417)

-Edge Enchanced ViT Framework
		Модели, основанные на архитектуре Vision Transformers показывают хорошую точность. Данное направление активно развивается и считается перспективным в машинном обучении. ViT 	обеспечивает глобальное контекстное понимание контента изображения, а модуль на краях фокусируется на локальных структурных непостоянствах, вычисляя карты различий края, дисперсии 	и производные оценки. (https://arxiv.org/html/2508.17877v1).
		Данная реализация также использует метод границ для повышения точности модели. Метод обнаружения границ фокусируется на поиске мест на изображении, где яркость или цвет 	заметно меняются от одной точки к другой. Если изменение небольшое, область кажется гладкой, если резкое — часто отмечает границу между двумя разными областями. 
		Модель обучена на наборе данных сайта Kaggle и наборе данных CIFAR-10. Точность модели достигает 97%. (https://arxiv.org/html/2508.17877v1#bib.bib18)


Примеры моделей, созданных для генерации изображений:

-Diffusion модели
		Диффузионные модели — один из ключевых классов генеративного ИИ. Они лежат в основе современных систем вроде Stable Diffusion, Midjourney и DALL·E. В основе метода — идея 	деградации и восстановления данных. Модель учится превращать случайный шум в осмысленные данные, имитируя процесс «обратного зашумления». Процесс делится на два этапа:
	1. Прямой процесс (forward process):
		Пошагово добавляется гауссовский шум к исходным данным (например, изображению), пока они не превратятся в полностью случайное распределение. Этот процесс фиксирован 		и не требует обучения.
	2. Обратный процесс (reverse process):
		Модель обучается убирать шум шаг за шагом, восстанавливая исходные данные. На каждом шаге сеть предсказывает, какой шум был добавлен, и вычитает его — двигаясь от хаоса к 	структуре. 	(https://habr.com/ru/articles/962176/)
	Примеры реализаций:
		-https://www.geeksforgeeks.org/artificial-intelligence/what-are-diffusion-models/
-GAN (генеративные состязательные нейросети)
	GAN состоит из двух основных моделей, которые работают вместе для создания реалистичных синтетических данных.
	1. Модель-генератор:
		Генератор — это глубокая нейронная сеть, которая принимает на вход случайный шум и генерирует реалистичные образцы данных, например изображения или текст. Она изучает 		закономерности, лежащие в основе данных, корректируя свои внутренние параметры в процессе обучения с помощью обратного распространения ошибки.
	2. Модель дискриминатора
		Дискриминатор действует как бинарный классификатор и помогает различать реальные и сгенерированные данные. В процессе обучения он совершенствует свои классификационные 	способности, уточняя параметры для более точного выявления поддельных образцов. При работе с данными изображений дискриминатор использует свёрточные слои или другие 			подходящие архитектуры, которые помогают извлекать признаки и повышать эффективность модели.
	Пошаговый процесс работы GAN:
	1. Первый шаг генератора
	2. Ход дискриминатора
	3. Состязательное обучение
	4. Улучшение генератора
	5. Адаптация дискриминатора
	6. Повышение эффективности тренировок
	(https://www.geeksforgeeks.org/deep-learning/generative-adversarial-network-gan/)
	Примеры реализаций:
		-https://www.geeksforgeeks.org/deep-learning/generative-adversarial-network-gan/
